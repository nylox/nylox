# Author: Salo Shp <saloshp@gmail.com>
#
#    This file is part of Munio. <https://github.com/salosh/munio.git>
#
#    Munio is free software: you can redistribute it and/or modify
#    it under the terms of the GNU General Public License as published by
#    the Free Software Foundation, either version 3 of the License, or
#    (at your option) any later version.
#
#    Munio is distributed in the hope that it will be useful,
#    but WITHOUT ANY WARRANTY; without even the implied warranty of
#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#    GNU General Public License for more details.
#
#    You should have received a copy of the GNU General Public License
#    along with Munio.  If not, see <http://www.gnu.org/licenses/>.
#

---
- name: "Download requirements"
  include_tasks: "{{ role_path }}/../common/tasks/requirements.yml"
  when:
  - "connectivity_mode == 'online'"
  tags:
  - reqs

# TODO add group
- name: "Add user '{{ conf.username }}'"
  user:
    name:  "{{ conf.username }}"
    state: present
  tags:
  - conf

- name: "Extract binary '{{ requirements.binary.name }}'"
  unarchive:
    src:  "{{ requirements.binary.local_path }}"
    dest: /usr/bin
    mode: "u=rwx,g=rx,o=rx"
  tags:
  - bin

- name: "Deploy service file"
  template:
    src:   consul_systemd.j2
    dest:  /etc/systemd/system/consul.service
    owner: root
    group: root
    mode:  "u=rw,g=r,o=r"
  tags:
  - service

- name: "Stop service"
  service:
    name:    "{{ item }}"
    state:   stopped
    enabled: no
  with_items:
  - "{{ conf.services }}"
  tags:
  - service

- name: "Delete configuration directories"
  file:
    dest:  "{{ item }}"
    state: absent
  with_items:
  - "{{ conf.conf_dir }}"
  - "{{ conf.root_dir }}"
  - /var/consul/raft/peers.json
  - /var/consul/raft/raft.db
  - /var/consul/serf/local.keyring
  - /var/consul/raft/snapshots
  tags:
  - clear

- name: "Delete previous snapshot files"
  file:
    path:  "{{ item }}"
    state: absent
  with_fileglob:
  - /var/consul/raft/snapshots/*
  tags:
  - clear

- name: "Create configuration directories"
  file:
    path:  "{{ item }}"
    state: "directory"
    owner: "{{ conf.username }}"
    group: "{{ conf.groupname }}"
  with_items:
  - "{{ conf.conf_dir }}"
  - "{{ conf.conf_dir }}/ssl"
  - "{{ conf.root_dir }}"
  - /var/log/consul
  - /var/consul
  - /var/consul/raft/snapshots
  tags:
  - conf

- name: "Slurp Consul key"
  slurp:
    src: "/var/lib/ca/intermediate/private/consul.key"
  register: consul_key
  delegate_to: "{{ groups['rootca-nodes'][0] }}"
  run_once: true
  tags:
  - init

- name: "Distribute Consul key to all nodes"
  copy:
    content: "{{ consul_key['content'] | b64decode }}"
    dest:    "/etc/consul/ssl/consul.key"
    owner: "{{ conf.username }}"
    group: "{{ conf.groupname }}"
    mode:    "u=r,g=,o="
    force:   yes
  tags:
  - init

- name: "Slurp CA cert"
  slurp:
    src: "/var/lib/ca/intermediate/certs/ca.crt"
  register: ca_cert
  delegate_to: "{{ groups['rootca-nodes'][0] }}"
  run_once: true
  tags:
  - init

- name: "Distribute CA cert to all nodes"
  copy:
    content: "{{ ca_cert['content'] | b64decode }}"
    dest:    "/etc/consul/ssl/ca.crt"
    owner: "{{ conf.username }}"
    group: "{{ conf.groupname }}"
    mode:    "u=r,g=,o="
    force:   yes
  tags:
  - init

- name: "Slurp Consul cert"
  slurp:
    src: "/var/lib/ca/intermediate/certs/consul.crt"
  register: consul_cert
  delegate_to: "{{ groups['rootca-nodes'][0] }}"
  run_once: true
  tags:
  - init

- name: "Distribute Consul key to all nodes"
  copy:
    content: "{{ consul_cert['content'] | b64decode }}"
    dest:    "/etc/consul/ssl/consul.crt"
    owner: "{{ conf.username }}"
    group: "{{ conf.groupname }}"
    mode:    "u=r,g=,o="
    force:   yes
  tags:
  - init

- name: "Deploy configuration"
  template:
    src:   "{{ conf.conf_file }}.j2"
    dest:  "{{ conf.conf_dir }}/{{ conf.conf_file }}"
    owner: "{{ conf.username }}"
    group: "{{ conf.groupname }}"
    mode:  "u=rw,g=r,o=r"
    force: yes
  tags:
  - conf

- name: "Deploy watches configuration"
  template:
    src:   "{{ item }}.j2"
    dest:  "{{ conf.root_dir }}/{{ item }}"
    owner: "{{ conf.username }}"
    group: "{{ conf.groupname }}"
    mode:  "u=rw,g=r,o=r"
    force: yes
  with_items:
  - "watches.json"
  tags:
  - conf

- name: "Deploy daemon additional configuration"
  template:
    src:   "service.json.j2"
    dest:  "{{ conf.root_dir }}/svc_{{ iteritem }}.json"
    owner: "{{ conf.username }}"
    group: "{{ conf.groupname }}"
    mode:  "u=rw,g=r,o=r"
    force: yes
  with_items:
  - "{{ lb_services.keys() | sort }}"
  loop_control:
    loop_var: "iteritem"
  when:
  - lb_services[iteritem].apply_to | default('') in group_names
  - "service_discovery_provider == 'consul' or iteritem == 'vault'"
  tags:
  - conf

- name: "Validate configuration"
  shell:
    consul validate "{{ conf.root_dir }}"  "{{ conf.conf_dir }}"
  tags:
  - verify

- name: "Deploy consul-watcher-utils"
  template:
    src: "{{ item }}"
    dest: "/usr/bin/cwu"
    owner: root
    group: root
    mode: "u=rwx,g=rx,o=rx"
    force: yes
  with_items:
  - "consul-watcher-utils"
  tags:
  - conf

- name: "Final state for service - {{ service_final.state }}"
  service:
    name:    "{{ item }}"
    state:   "{{ service_final.state }}"
    enabled: "{{ service_final.enabled }}"
  with_items:
  - "{{ conf.services }}"
  tags:
  - service

- name: "Wait for ports - server ports"
  wait_for:
    host:    "{{ item.host }}"
    port:    "{{ item.port }}"
    state:   started
    timeout: 5
  with_items:
  - host: "{{ bind_host }}"
    port: "8300"
  - host: "{{ bind_host }}"
    port: "8302"
  loop_control:
    label: "{{ item.host }}:{{ item.port }}"
  when:
  - "service_final.state != 'stopped'"
  - "consul_config_mode == 'server'"
  tags:
  - service
  - verify

- name: "Wait for ports - all Consul nodes ports"
  wait_for:
    host:    "{{ item.host }}"
    port:    "{{ item.port }}"
    state:   started
    timeout: 15
  with_items:
  - host: "{{ bind_host }}"
    port: "8301"  
  - host: "{{ bind_host }}"
    port: "8500"
  - host: "{{ bind_host }}"
    port: "8600"
  loop_control:
    label: "{{ item.host }}:{{ item.port }}"
  when:
  - "service_final.state != 'stopped'"
  tags:
  - service
  - verify

- name: "Join cluster via primary node '{{ primary_node }}'"
  vars:
    primary_node: "{{ groups['consul-nodes'][0] }}"
  shell:
    "{{ item }}"
  with_items:
  - "/usr/bin/consul join {{ primary_node }}"
  when:
  - not is_primary
  tags:
  - service
